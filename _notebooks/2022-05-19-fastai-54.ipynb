{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Deep Learning for Coders Course - Lesson 4\n",
    "\n",
    "> \"This blog-post series captures my weekly notes while I attend the [fastaiv5 course conducted by University of Queensland with fast.ai](https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai). So off to week 4, where we will get started with NLP and transformers\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- hide_binder_badge: true\n",
    "- hide_deepnote_badge: true\n",
    "- comments: true\n",
    "- author: Kurian Benoy\n",
    "- categories: [fastai, fastbook]                                                         \n",
    "- hide: false\n",
    "- search_exclude: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to lesson\n",
    "\n",
    "Almost 100+ people watched live virtually and lesson were held live in front of a bunch of audience in University of Queensland. Prof. John Williams opened session by telling about filling a separate form, for people interested in attending the hackathon organized end of the course.\n",
    "\n",
    "During the start Jeremy mentioned about if someone could organize a online hackathon by community for folks attending remotely as well. As right now Jeremy and John doesn't have the capacity to organize one.\n",
    "\n",
    "## About using a different framework - Transformers\n",
    "\n",
    "Since this course if fastai, it may well bit weird when we are today going to use a different library\n",
    "called `transformers`.\n",
    "\n",
    "> Important: As practitioners, it's very important for us to learn more than one framework.\n",
    "\n",
    "**Note: Differences with fastai and transformers:**\n",
    "\n",
    "1. Transformers provide lot of state of art models, and the tokenizers library build with rest is really good at the moment.\n",
    "2. It's good to get exposure to a library which is not so layered like fastai, which makes fast.ai super useful for beginners.\n",
    "\n",
    "## ULMfit architecture\n",
    "\n",
    "The architecture, which first using fine turning got great results in NLP. Consider finetuning, as \n",
    "tweaking functions in such a way when if you are already some values of a, b lever are good and optimal for a particular function. Then tweaking value of c is easier right?\n",
    "\n",
    "ULMfit archtecture consits of three steps:\n",
    "\n",
    "- Training a language models with general dataset like wikipedia. So it get so good in predicting these\n",
    "words. Now in transformers, one big differnce is we use masking instead of predicting next word\n",
    "- IMDB lnagage build a language model, build on top of LM for wikipedia\n",
    "- In three step, is where model classifier comes and based on this label sentences as postive, negative etc.\n",
    "\n",
    "\n",
    "## Fundamentals about learning\n",
    "\n",
    "Four fundamental libraries:\n",
    "\n",
    "1. NumPy\n",
    "2. Pandas\n",
    "3. matplotlib\n",
    "4. Pytorch\n",
    "\n",
    "> Important: It looks pretty cool, if you build the state of art stuff. Yet if you don't know fundamentals, you will encounter trouble. So i will recommend you to get started by first completely reading the Fast book, then the Macinskey book on python3\n",
    "\n",
    "## Tokenization of dataset\n",
    "\n",
    "It's been only a year or two since NLP has been getting good results, for computer vision things\n",
    "are being optimistic for a long time now.\n",
    "\n",
    "Tokenization, is converting the text blurbs into a set of small tokens.\n",
    "Numericalization is the process of converting these tokensto number for models to train\n",
    "\n",
    "Patent jeremy searched model hub, found a lot of cool dataset\n",
    "\n",
    "## Test, Validation Dataset\n",
    "\n",
    "Very important concept. Keep a separate hold out dataset for further user.\n",
    "\n",
    "\n",
    "## Understanding metrics\n",
    "\n",
    "Metrics in real world is a couse fo r bias, so look at it's consequence by reading rachel thomas articles\n",
    "\n",
    "> talked about why metrics in realworld has some harmful effects\n",
    "\n",
    "> Understanding metrics is very key, even if you make small error in peason comp you will notice a hugh bump in learning ML\n",
    "\n",
    "## Training the model\n",
    "\n",
    "> Why we used just label = 1\n",
    "\n",
    "very similar to fastai comp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0rc2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c158fc4cc62aaf8efdf4e544f2c60f81becbac2749f1463ef4629eb66a90f1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
