{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Deep Learning for Coders Course - Lesson 2\n",
    "\n",
    "> \"This blog-post series captures my weekly notes while I attend the [fastaiv5 course conducted by University of Queensland with fast.ai](https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai). So off to week2 where we learn about productionizing ML models and how to get good accuracy.\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- hide_binder_badge: true\n",
    "- comments: true\n",
    "- author: Kurian Benoy\n",
    "- categories: [fastai, fastbook]                                                         \n",
    "- hide: false\n",
    "- search_exclude: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Setup\n",
    "\n",
    "Jeremy was taking this session from his home, as the venue in University of queensland was already\n",
    "booked by someone else. Jeremy was really really pumped for this lesson and it's like going to the early days of fast.ai with lot of super exciting work happening.\n",
    "\n",
    "> twitter: https://twitter.com/bhutanisanyam1/status/1521511103406043137\n",
    "\n",
    "\n",
    "Jeremy mentioned some technique on using Jupyter notebooks, and asked to take a look at jupyter extensions. The navigation section and how to collapse headings was explained during class. [24:00]\n",
    "\n",
    "## Fastbook Chapter 2\n",
    "\n",
    "This week we started by taking a look at putting model in production using fastai. This was the same\n",
    "thing which is covered in chapter 2 of Deep Learning book To build grizzly bears and teddy bears classifier.\n",
    "\n",
    "Few things have changed in book in this version:\n",
    "\n",
    "- using `search_images_ddg` instead of bing search apis\n",
    "- using `huggingfaces spaces` as deployment instead of voila even though it's still works\n",
    "\n",
    "`RandomResizedCrop using fastai had some questions from Alex:`\n",
    "\n",
    "Does randomresized crop duplicate the image -- i.e. you get multiple copies and you ensure that all the parts of the image are used in training? or does it just make one crop? Jeremy answered it in video at [32:30]. \n",
    "\n",
    "Sanyam mentioned that RandomResized crop as a augmentation is very helpful:\n",
    "\n",
    "> Actually this technique is SUPER helpful-in a recent interview, Chris Deotte (4x Grandmaster) shared how these resizing techniques helped them win a solo gold. This was in the petfinder Kaggle competition (2nd run of the comp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Jeremy is running on a laptop with 4GB GPU. Jeremy says in GPU, just run one thing at a time else you will get CUDA error.\n",
    "\n",
    "## How to do fast.ai course\n",
    "\n",
    "**Tips for people in Yellow bucket:**\n",
    "\n",
    "> Note: If you are in yellow, always stop try. First go ahead and watch video fully without try anything in jupyter. Then watch again and follow the course. This is an unusual way but it's very effective.\n",
    "\n",
    "I asked [Wayde Gilliam](https://twitter.com/waydegilliam/), a long term fastai community member after the lesson about his process of watching lectures. He was gracious enough to share it with mith\n",
    "\n",
    "> Important: 1. Watch the livestream and jot down timestamp to go back to for anything I found interesting in journal A (or just a piece of paper)\n",
    "\n",
    "> Important: 2. Go back thru video after 2-3 days, hit those spots I noted during the livestream.  Will write detailed notes in another Journal (we'll call that journal B)\n",
    "\n",
    "> Note: There's too much info to digest in real-time so this approach works well and its what I've been doing for 4-5 yrs.\n",
    "\n",
    "\n",
    "## Huggingface spaces\n",
    "\n",
    "Jeremy pointed to tanishq tutorial on [Gradio + HuggingFace Spaces](https://tmabraham.github.io/blog/gradio_hf_spaces_tutorial).\n",
    "\n",
    "Also Jeremy mentioned some good tools which are useful:\n",
    "- Github Desktop: Hamel who was a employee in github previously, is even using github desktop. Some complicated stuff in git can be solved using this tool. Even knowing terminal is cool.\n",
    "- WSL: As a datascientist, you spend a lot of time in terminals. Just use ubuntu with windows terminal. Any time Jeremy shows in terminal, he just uses windows terminal.\n",
    "\n",
    "Jeremy like Windows due to easiness in streaming and recording capabilities. Yet then there is linux environment with a good Deep learning machine.\n",
    "\n",
    "Quick gradio demo\n",
    "Catas vs Dog inference\n",
    "\n",
    "Jupyter notebooks debugging with magic methods %magic\n",
    "\n",
    "Look at dict, numbers. Changing images predicted and issue with gradio using function to\n",
    "return gradio docs. Tensors is not supported at moment.\n",
    "\n",
    "Jeremy with cats vs dogs classifier create a spaces. Jeremy's daughter when realised he is building\n",
    "such a classifier googled something which is a mix of cat and dog. For that his initial prediction\n",
    "was like 50-50% for both cats and dogs.\n",
    "\n",
    "TODO: Look through Jeremy setup and how he worked with gradio in local [58:00 onwards 1:14:00]\n",
    "\n",
    "\n",
    "## fastsetup\n",
    "\n",
    "Installing python and jupyter-notebooks.\n",
    "\n",
    "https://github.com/fastai/fastsetup\n",
    "\n",
    "A big issue in laptops. There is a setup_conda.sh. In linux or mac, don't use that python.\n",
    "\n",
    "That Python will mess stuff up. Running conda based systems is good.\n",
    "\n",
    "Run mamba install fastai\n",
    "mamba install -c fastchan jupyter nbdev\n",
    "\n",
    "Setting up huggingspace. Then using git & conda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying gradio API with github Pages\n",
    "\n",
    "[An example API in gradio](https://hf.space/embed/kurianbenoy/audioclassification/api)\n",
    "[Example Jeremy showcased](https://github.com/fastai/tinypets)\n",
    "\n",
    "With live demo, we could have easily used it.\n",
    "```\n",
    "fetch('https://hf.space/embed/kurianbenoy/audioclassification/+/api/predict/', { method: \"POST\", body: JSON.stringify({\"data\":[ {\"data\": null, \"is_example\": true, \"name\": \"000003.ogg\"}\n",
    "\n",
    "]}), headers: { \"Content-Type\": \"application/json\" } }).then(function(response) { return response.json(); }).then(function(json_response){ console.log(json_response) })\n",
    "```\n",
    "\n",
    "\n",
    "How do you create a website for website. Without any software, you can run this file. That's so\n",
    "cool about javascript. There is something cool called github pages\n",
    "\n",
    "He used alembic theme. With a particular  configuration. At top of any github pages, you should\n",
    "add three dashes. The world of javascript apps, he build this cool apps.\n",
    "\n",
    "\n",
    "> The magic of using gradio APIs can be summarized as the following. It exposes a reliable way of sharing microservices. With this if you are just creating any hugging face spaces, with that APIs. You can use it any websites, apps etc. It looks to me there is no limitation with using Gradio API at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
