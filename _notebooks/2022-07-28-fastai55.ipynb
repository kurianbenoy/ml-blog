{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788846f2-148f-4883-85f8-93bcd1abbd88",
   "metadata": {},
   "source": [
    "# Practical Deep Learning for Coders Course - Tabular Models (Linear Regression & Random Forests)\n",
    "\n",
    "> \"This blog-post series captures my weekly notes while I attend the [fastaiv5 course conducted by University of Queensland with fast.ai](https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai). So off to week 5, where we will get started with NLP and transformers\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- hide_binder_badge: true\n",
    "- hide_deepnote_badge: true\n",
    "- comments: true\n",
    "- image: images/monsoon.jpg\n",
    "- author: Kurian Benoy\n",
    "- categories: [fastai, fastaicourse]                                                         \n",
    "- hide: true\n",
    "- search_exclude: false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651a794-9dfd-411e-8513-0a392eef47f3",
   "metadata": {},
   "source": [
    "- Pandas, never delete columns\n",
    "- replace missing values using model. multiple modes first element\n",
    "- fillna with modes with simplest most way\n",
    "- In first baseline model, don't do complicated things at the start. \n",
    "- Don't discard data\n",
    "- fastai library tabular implementation\n",
    "- Long tailed distribution(how it's done, we use logs in maths a lot)\n",
    "- dummy variables for Pclass\n",
    "- using pytorch to turn linear\n",
    "- tensor is what mathematicians call tensor. APL came with the idea called tensor, tensor analysis\n",
    "- Understanding how much the data/model behaves is very important\n",
    "- matrix, vector(be familiar with jargons)\n",
    "- matrix * vector product(comes from APL)\n",
    "- looping 891 times, uses more like math\n",
    "- coding with explaination, then writing functions. Such a huge productivity win."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d392d-86b6-439d-9ec1-8742f9b0ffcd",
   "metadata": {},
   "source": [
    "**Doing gradient descent step**\n",
    "\n",
    "- pytorch jargon\n",
    "\n",
    "In titanic, it's very easy to create a random split. Jeremy was involved in creating this dataset, when he founded fastai\n",
    "\n",
    "**Training linear model**\n",
    "\n",
    "- accuracy doesn't have a sensible gradient\n",
    "- but we should measure accuracy to get a good understanding\n",
    "- measuring accuracy, in his code. There is a lot of prose. The function doesn't require comments.\n",
    "\n",
    "Using Sigmoid for survival\n",
    "\n",
    "- sympy simbolic python has a really good way\n",
    "- calc_preds(), the sigmoid python and how it's cool\n",
    "- accuracy and always improved\n",
    "- for binary depended variable, why it's good. Remember that chucking sigmoid gives 0.7% improvements in increase\n",
    "- Input & output philosophy\n",
    "- feature engineering in test data with get_dummies? In fastai it has an other category by default\n",
    "\n",
    "training set change and fill values\n",
    "\n",
    "- column vector, matrix of rank2\n",
    "train_dep[:, None] - trailing unit axis\n",
    "- build neural networks with one hidden, then build deep learning with multiple layers\n",
    "- WHen you run yourself, you realize our models are really good\n",
    "- Deep learning competition, with very few columns, it's hard to get good results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14425aa6-2656-49c4-a56b-fff5e07a2ed3",
   "metadata": {},
   "source": [
    "Framework notebook:\n",
    "\n",
    "pandas\n",
    "feature engineering didn't understand\n",
    "\n",
    "test_dl(create entire preprocessing used in same framework)\n",
    "\n",
    "## Ensembling \n",
    "\n",
    "Is created, get the prediction and stack the predictions\n",
    "\n",
    "get average predictions of 5 seconds, with this we get top 25%\n",
    "\n",
    "## Random forests\n",
    "\n",
    "really popularly algos and very popular in 2000s\n",
    "\n",
    "split rows into two group\n",
    "binary-split model\n",
    "\n",
    "Kernel density plots\n",
    "\n",
    "single method, ridiculously simple method in 1990 was 1 R. Then hyper plot to random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c8c69-1283-4562-b76d-afd5c1c79bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
